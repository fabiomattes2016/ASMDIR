{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNXvma7AE25FqMf7zEl7C4x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fabiomattes2016/ASMDIR/blob/master/Comparador_de_PDF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "r_1cW6lsIUYm"
      },
      "outputs": [],
      "source": [
        "#!pip install PyPDF2\n",
        "#!pip install scikit-learn\n",
        "\n",
        "import PyPDF2\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "#nltk.download('punkt')\n",
        "#nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "ssK876hKKXs6"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_file1 = open('/content/35238628948a.pdf', 'rb')\n",
        "pdf_file2 = open('/content/FichaSimplificada.pdf', 'rb')"
      ],
      "metadata": {
        "id": "f3Fx33q0Ic3x"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_reader1 = PyPDF2.PdfReader(pdf_file1)\n",
        "pdf_reader2 = PyPDF2.PdfReader(pdf_file2)"
      ],
      "metadata": {
        "id": "ksamQO1cJLp_"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_pages1 = len(pdf_reader1.pages)\n",
        "num_pages2 = len(pdf_reader2.pages)\n",
        "print(num_pages1, num_pages2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOXZjLQsJVZX",
        "outputId": "4194f5e4-4db8-4680-9ea7-9b3dfa088070"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text1 = ''\n",
        "text2 = ''"
      ],
      "metadata": {
        "id": "96JTyc9-JnZX"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extrair o texto de cada página do documento 1\n",
        "for page in range(num_pages1):\n",
        "    page_obj1 = pdf_reader1.pages[page]\n",
        "    text1 += page_obj1.extract_text()"
      ],
      "metadata": {
        "id": "h3raoPkCJOFe"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extrair o texto de cada página do documento 2\n",
        "for page in range(num_pages2):\n",
        "    page_obj2 = pdf_reader2.pages[page]\n",
        "    text2 += page_obj2.extract_text()"
      ],
      "metadata": {
        "id": "q7y72a35J5N2"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_file1.close()\n",
        "pdf_file2.close()"
      ],
      "metadata": {
        "id": "lCSkgqdiJ_fO"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remover pontuação e caracteres especiais\n",
        "text1 = text1.translate(str.maketrans('', '', string.punctuation))\n",
        "text2 = text2.translate(str.maketrans('', '', string.punctuation))"
      ],
      "metadata": {
        "id": "9oZC7z0fKB1f"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converter todas as letras em minúsculas\n",
        "text1 = text1.lower()\n",
        "text2 = text2.lower()"
      ],
      "metadata": {
        "id": "aGKweeBmKFfn"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizar o texto em palavras\n",
        "tokens1 = word_tokenize(text1)\n",
        "tokens2 = word_tokenize(text2)"
      ],
      "metadata": {
        "id": "SWs1p-i_KHtf"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remover stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_tokens1 = [w for w in tokens1 if not w in stop_words]\n",
        "filtered_tokens2 = [w for w in tokens2 if not w in stop_words]"
      ],
      "metadata": {
        "id": "x01L460iKh1H"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stemming das palavras\n",
        "ps = PorterStemmer()\n",
        "stemmed_tokens1 = [ps.stem(w) for w in filtered_tokens1]\n",
        "stemmed_tokens2 = [ps.stem(w) for w in filtered_tokens2]"
      ],
      "metadata": {
        "id": "CJSMhHRSKp14"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Juntar as palavras novamente em texto\n",
        "processed_text1 = ' '.join(stemmed_tokens1)\n",
        "processed_text2 = ' '.join(stemmed_tokens2)"
      ],
      "metadata": {
        "id": "O4-HG7vMKsUX"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vetorizar o texto usando o TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectors = vectorizer.fit_transform([processed_text1, processed_text2])"
      ],
      "metadata": {
        "id": "yjbYBBA7Kucs"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular a similaridade de cosseno entre os vetores\n",
        "similarity = cosine_similarity(vectors)[0][1]"
      ],
      "metadata": {
        "id": "Ix-gAAaBKxDf"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('A similaridade entre os documentos é: ', similarity * 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgP68MQCKzVv",
        "outputId": "a9a411e6-640f-4229-fc6e-8797c4dccd57"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A similaridade entre os documentos é:  75.23187561862608\n"
          ]
        }
      ]
    }
  ]
}